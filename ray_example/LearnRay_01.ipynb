{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray AI Runtime Quick Start\n",
    "To use Ray’s AI Runtime install Ray with the optional extra air packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/caihaocui/.pyenv/versions/ray-example/bin/python\n"
     ]
    }
   ],
   "source": [
    "!pyenv which python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into a Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 12:56:48,927\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2023-03-05 12:56:51,023\tWARNING read_api.py:330 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset]: Run `pip install tqdm` to enable progress reporting.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "# Load data.\n",
    "dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")\n",
    "\n",
    "# Split data into train and validation.\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# Create a test dataset by dropping the target column.\n",
    "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessor to scale some columns.\n",
    "from ray.data.preprocessors import StandardScaler\n",
    "\n",
    "preprocessor = StandardScaler(columns=[\"mean radius\", \"mean texture\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model with an XGBoostTrainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ ---------\n",
      "aiohttp                  3.8.4\n",
      "aiohttp-cors             0.7.0\n",
      "aiorwlock                1.3.0\n",
      "aiosignal                1.3.1\n",
      "anyio                    3.6.2\n",
      "appnope                  0.1.3\n",
      "asttokens                2.2.1\n",
      "async-timeout            4.0.2\n",
      "attrs                    22.2.0\n",
      "backcall                 0.2.0\n",
      "blessed                  1.20.0\n",
      "cachetools               5.3.0\n",
      "certifi                  2022.12.7\n",
      "charset-normalizer       3.0.1\n",
      "click                    8.1.3\n",
      "colorful                 0.5.5\n",
      "comm                     0.1.2\n",
      "debugpy                  1.6.6\n",
      "decorator                5.1.1\n",
      "distlib                  0.3.6\n",
      "executing                1.2.0\n",
      "fastapi                  0.92.0\n",
      "filelock                 3.9.0\n",
      "frozenlist               1.3.3\n",
      "fsspec                   2023.3.0\n",
      "google-api-core          2.11.0\n",
      "google-auth              2.16.2\n",
      "googleapis-common-protos 1.58.0\n",
      "gpustat                  1.0.0\n",
      "grpcio                   1.49.1\n",
      "h11                      0.14.0\n",
      "idna                     3.4\n",
      "importlib-metadata       6.0.0\n",
      "ipykernel                6.21.2\n",
      "ipython                  8.11.0\n",
      "jedi                     0.18.2\n",
      "jsonschema               4.17.3\n",
      "jupyter_client           8.0.3\n",
      "jupyter_core             5.2.0\n",
      "matplotlib-inline        0.1.6\n",
      "msgpack                  1.0.4\n",
      "multidict                6.0.4\n",
      "nest-asyncio             1.5.6\n",
      "numpy                    1.24.2\n",
      "nvidia-ml-py             11.495.46\n",
      "opencensus               0.11.1\n",
      "opencensus-context       0.1.3\n",
      "packaging                23.0\n",
      "pandas                   1.5.3\n",
      "parso                    0.8.3\n",
      "pexpect                  4.8.0\n",
      "pickleshare              0.7.5\n",
      "pip                      23.0.1\n",
      "platformdirs             3.1.0\n",
      "prometheus-client        0.16.0\n",
      "prompt-toolkit           3.0.38\n",
      "protobuf                 3.20.3\n",
      "psutil                   5.9.4\n",
      "ptyprocess               0.7.0\n",
      "pure-eval                0.2.2\n",
      "py-spy                   0.3.14\n",
      "pyarrow                  11.0.0\n",
      "pyasn1                   0.4.8\n",
      "pyasn1-modules           0.2.8\n",
      "pydantic                 1.10.5\n",
      "Pygments                 2.14.0\n",
      "pyrsistent               0.19.3\n",
      "python-dateutil          2.8.2\n",
      "pytz                     2022.7.1\n",
      "PyYAML                   6.0\n",
      "pyzmq                    25.0.0\n",
      "ray                      2.3.0\n",
      "requests                 2.28.2\n",
      "rsa                      4.9\n",
      "setuptools               67.1.0\n",
      "six                      1.16.0\n",
      "smart-open               6.3.0\n",
      "sniffio                  1.3.0\n",
      "stack-data               0.6.2\n",
      "starlette                0.25.0\n",
      "tabulate                 0.9.0\n",
      "tensorboardX             2.6\n",
      "tornado                  6.2\n",
      "traitlets                5.9.0\n",
      "typing_extensions        4.5.0\n",
      "urllib3                  1.26.14\n",
      "uvicorn                  0.20.0\n",
      "virtualenv               20.20.0\n",
      "wcwidth                  0.2.6\n",
      "wheel                    0.38.4\n",
      "yarl                     1.8.2\n",
      "zipp                     3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mair\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ScalingConfig\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBoostTrainer\n\u001b[1;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m XGBoostTrainer(\n\u001b[1;32m      5\u001b[0m     scaling_config\u001b[39m=\u001b[39mScalingConfig(\n\u001b[1;32m      6\u001b[0m         \u001b[39m# Number of workers to use for data parallelism.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     preprocessor\u001b[39m=\u001b[39mpreprocessor,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ray-example/lib/python3.9/site-packages/ray/train/xgboost/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgboost\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgboost_checkpoint\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBoostCheckpoint\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgboost\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgboost_predictor\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBoostPredictor\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgboost\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxgboost_trainer\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBoostTrainer\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ray-example/lib/python3.9/site-packages/ray/train/xgboost/xgboost_checkpoint.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtempfile\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Optional\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mxgboost\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mair\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpointing\u001b[39;00m \u001b[39mimport\u001b[39;00m save_preprocessor_to_dir\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mair\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m \u001b[39mimport\u001b[39;00m Checkpoint\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=ScalingConfig(\n",
    "        # Number of workers to use for data parallelism.\n",
    "        num_workers=2,\n",
    "        # Whether to use GPU acceleration.\n",
    "        use_gpu=False,\n",
    "        # Make sure to leave some CPUs free for Ray Data operations.\n",
    "        _max_cpu_fraction_per_node=0.9,\n",
    "    ),\n",
    "    label_column=\"target\",\n",
    "    num_boost_round=20,\n",
    "    params={\n",
    "        # XGBoost specific params\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        # \"tree_method\": \"gpu_hist\",  # uncomment this to use GPUs.\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    },\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the parameters for tuning:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "param_space = {\"params\": {\"max_depth\": tune.randint(1, 9)}}\n",
    "metric = \"train-logloss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.tuner import Tuner, TuneConfig\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    "    tune_config=TuneConfig(num_samples=5, metric=metric, mode=\"min\"),\n",
    ")\n",
    "result_grid = tuner.fit()\n",
    "best_result = result_grid.get_best_result()\n",
    "print(\"Best result:\", best_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the trained model for batch prediction with a BatchPredictor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.xgboost import XGBoostPredictor\n",
    "\n",
    "# You can also create a checkpoint from a trained model using\n",
    "# `XGBoostCheckpoint.from_model`.\n",
    "checkpoint = best_result.checkpoint\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(checkpoint, XGBoostPredictor)\n",
    "\n",
    "predicted_probabilities = batch_predictor.predict(test_dataset)\n",
    "predicted_probabilities.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
